import cv2
import numpy as np
import argparse
import os
import concurrent.futures
import ffmpeg

def process_frame_cpu(frame):
    """Apply cartoon effect to a frame using CPU processing."""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray = cv2.bilateralFilter(gray, d=9, sigmaColor=75, sigmaSpace=75)
    gray = cv2.medianBlur(gray, 7)
    edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)
    cartoon = cv2.bitwise_and(frame, frame, mask=edges)
    return cartoon

def process_frame_gpu(frame_gpu):
    """Apply cartoon effect to a frame using GPU processing."""
    gray = cv2.cuda.cvtColor(frame_gpu, cv2.COLOR_BGR2GRAY)
    gray = cv2.cuda.bilateralFilter(gray, d=9, sigmaColor=75, sigmaSpace=75)
    gray = cv2.cuda.medianBlur(gray, 7)
    edges = cv2.cuda.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)
    cartoon = cv2.cuda.bitwise_and(frame_gpu, frame_gpu, mask=edges)
    return cartoon

def cartoonify_video(input_file, output_file=None, verbose=False, use_gpu=False):
    """
    Cartoonify a video file.

    Args:
        input_file (str): Input video file name.
        output_file (str, optional): Output video file name (default is autogenerated).
        verbose (bool, optional): Enable verbose mode.
        use_gpu (bool, optional): Use GPU for acceleration if available.

    Returns:
        None
    """
    def print_verbose(message):
        if verbose:
            print(message)

    # Open the video file using FFmpeg
    input_video = ffmpeg.input(input_file)

    # Get video properties using FFmpeg
    video_info = (
        input_video.output()
        .get_output_format()
        .get_args()
    )

    # Create FFmpeg process for writing the output video with the same encoding
    base_filename, file_extension = os.path.splitext(input_file)
    if output_file is None:
        output_file = f"{base_filename}_cartoon{file_extension}"

    output_video = (
        ffmpeg.output(
            input_video.video,
            output_file,
            *video_info,
        )
        .overwrite_output()
    )

    with ffmpeg.run(output_video, quiet=True, overwrite_output=True) as process:
        # Initialize video capture using OpenCV
        with cv2.VideoCapture(input_file) as cap:
            frame_queue = []
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                frame_queue.append(frame)

            def process_frame_with_queue(frame):
                if use_gpu:
                    frame_gpu = cv2.cuda_GpuMat()
                    frame_gpu.upload(frame)
                    cartoon_gpu = process_frame_gpu(frame_gpu)
                    cartoon = cartoon_gpu.download()
                else:
                    cartoon = process_frame_cpu(frame)
                return cartoon

            with concurrent.futures.ThreadPoolExecutor() as executor:
                results = list(executor.map(process_frame_with_queue, frame_queue))

            for cartoon in results:
                process.stdin.write(cartoon.tostring())

    print_verbose("Cartoonification completed.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Cartoonify a video file.")
    parser.add_argument("input_file", help="Input video file name")
    parser.add_argument("-o", "--output_file", help="Output video file name (optional)")
    parser.add_argument("-v", "--verbose", action="store_true", help="Enable verbose mode")
    parser.add_argument("--gpu", action="store_true", help="Use GPU for acceleration if available")
    args = parser.parse_args()

    cartoonify_video(args.input_file, args.output_file, args.verbose, args.gpu)
